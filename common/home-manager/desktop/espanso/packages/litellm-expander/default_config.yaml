# LiteLLM Configuration for Espanso

# Default provider and model to use
default_provider: "ollama"
default_model: "llama3:latest"

# Configuration for different providers
providers:
  ollama:
    api_base: "http://localhost:11434"
    models:
      default: "llama3:latest"
      fast: "llama3:8b"
      precise: "llama3:70b"
      
  openai:
    api_key: ""  # Set your API key here or in environment variables
    models:
      default: "gpt-3.5-turbo"
      fast: "gpt-3.5-turbo"
      precise: "gpt-4"
      
  openrouter:
    api_key: ""  # Set your API key here or in environment variables
    models:
      default: "anthropic/claude-3-sonnet"
      fast: "anthropic/claude-3-haiku"
      precise: "anthropic/claude-3-opus"
  
  nano-gpt:
    api_base: "https://nano-gpt.com"
    api_key: ""  # Set your API key here or in environment variables
    models:
      default: "TEE/llama-3.3-70b-instruct"
      fast: "TEE/llama-3.3-70b-instruct"  # Using same model for consistency
      precise: "TEE/llama-3.3-70b-instruct"  # Using same model for consistency
      
  claude:
    api_base: "https://api.anthropic.com/v1"
    api_key: ""  # Set your API key here
    models:
      default: "claude-3-sonnet-20240229"
      fast: "claude-3-haiku-20240307"
      precise: "claude-3-opus-20240229"
      
  perplexity:
    api_base: "https://api.perplexity.ai"
    api_key: ""  # Set your API key here
    models:
      default: "sonar-medium-online"
      fast: "sonar-small-online"
      precise: "sonar-large-online"

# Role-specific prompts for different use cases
roles:
  default: "You are a helpful assistant."
  spanish: "You are a helpful translator. Translate the following text to Spanish. Return only the translation without any additional text."
  french: "You are a helpful translator. Translate the following text to French. Return only the translation without any additional text."
  cli: "You are a CLI command generator. Generate a bash command based on this description. Return only the command without any explanation."
  emoji: "Convert the following text description into appropriate emojis only. Do not include any explanation:"

# General LLM parameters
temperature: 0.7
max_tokens: 1000